{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13=02-2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaD5XBr58BIZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# LOSSES\n",
    "# ============================================================\n",
    "\n",
    "def kl_loss(mean, logvar):\n",
    "    return -0.5 * torch.sum(\n",
    "        1 + logvar - mean.pow(2) - logvar.exp(),\n",
    "        dim=[1, 2, 3]\n",
    "    ).mean()\n",
    "\n",
    "def recon_loss(pred, target):\n",
    "    return F.l1_loss(pred, target)\n",
    "\n",
    "# ============================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================\n",
    "\n",
    "def show_grid(tensor, title=\"\"):\n",
    "    tensor = (tensor + 1) / 2\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "\n",
    "    grid = make_grid(tensor, nrow=8)\n",
    "    grid = grid.cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(grid.squeeze(), cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# STOCHASTICITY CHECK\n",
    "# ============================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def check_latent_stochasticity(vae, loader):\n",
    "    vae.eval()\n",
    "    batch = next(iter(loader))\n",
    "    x = batch[\"image\"].to(device)\n",
    "\n",
    "    mean, logvar = vae.encode(x)\n",
    "\n",
    "    z1 = vae.reparameterize(mean, logvar)\n",
    "    z2 = vae.reparameterize(mean, logvar)\n",
    "\n",
    "    diff = torch.mean(torch.abs(z1 - z2))\n",
    "    print(\"Latent stochastic difference:\", diff.item())\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN\n",
    "# ============================================================\n",
    "\n",
    "def train_vae(vae, train_loader, val_loader,\n",
    "              epochs=150, lr=1e-4,\n",
    "              out_dir=\"./vae_outputs\"):\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    preview_dir = os.path.join(out_dir, \"previews\")\n",
    "    os.makedirs(preview_dir, exist_ok=True)\n",
    "\n",
    "    vae = vae.to(device)\n",
    "\n",
    "    ckpt_file = os.path.join(out_dir, \"resume_checkpoint.pt\")\n",
    "    best_model = os.path.join(out_dir, \"vae_best.pth\")\n",
    "\n",
    "    optimizer = torch.optim.AdamW(vae.parameters(), lr=lr)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    start_epoch = 1\n",
    "    best_val = float(\"inf\")\n",
    "\n",
    "    # Resume training\n",
    "    if os.path.exists(ckpt_file):\n",
    "        ckpt = torch.load(ckpt_file, map_location=device)\n",
    "        vae.load_state_dict(ckpt[\"model\"])\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "        if \"scaler\" in ckpt:\n",
    "            scaler.load_state_dict(ckpt[\"scaler\"])\n",
    "        start_epoch = ckpt[\"epoch\"] + 1\n",
    "        best_val = ckpt[\"best_val\"]\n",
    "        print(\"Resuming from epoch\", start_epoch)\n",
    "\n",
    "    preview = next(iter(val_loader))[\"image\"]\n",
    "    preview = preview[:min(8, preview.size(0))].to(device)\n",
    "\n",
    "    # ========================================================\n",
    "    # TRAIN LOOP\n",
    "    # ========================================================\n",
    "\n",
    "    for epoch in range(start_epoch, epochs + 1):\n",
    "\n",
    "        # KL warmup\n",
    "        beta = 0.01 * min(1.0, epoch / 100)\n",
    "\n",
    "        vae.train()\n",
    "        total_recon = 0\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"[TRAIN] Epoch {epoch}/{epochs}\")\n",
    "\n",
    "        for batch in pbar:\n",
    "            img = batch[\"image\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "                recon, mean, logvar = vae(img)\n",
    "                loss_r = recon_loss(recon, img)\n",
    "                loss_k = kl_loss(mean, logvar)\n",
    "                loss = 10 * loss_r + beta * loss_k\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(vae.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_recon += loss_r.item()\n",
    "\n",
    "            pbar.set_postfix(L1=f\"{loss_r.item():.4f}\",\n",
    "                             KL=f\"{loss_k.item():.4f}\",\n",
    "                             beta=f\"{beta:.5f}\")\n",
    "\n",
    "        total_recon /= len(train_loader)\n",
    "\n",
    "        # ================= VALIDATION (deterministic) =================\n",
    "\n",
    "        vae.eval()\n",
    "        val_recon = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                img = batch[\"image\"].to(device)\n",
    "\n",
    "                mean, logvar = vae.encode(img)\n",
    "                recon = vae.decode(mean)\n",
    "\n",
    "                val_recon += recon_loss(recon, img).item()\n",
    "\n",
    "        val_recon /= len(val_loader)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}\")\n",
    "        print(f\"Train L1: {total_recon:.4f} | Val L1: {val_recon:.4f}\")\n",
    "\n",
    "        # ================= PREVIEW (deterministic) =================\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mean, logvar = vae.encode(preview)\n",
    "            recon = vae.decode(mean)\n",
    "\n",
    "        vis = torch.cat([preview, recon], dim=0)\n",
    "\n",
    "        save_path = os.path.join(preview_dir, f\"epoch_{epoch}.png\")\n",
    "        save_image((vis + 1) / 2, save_path, nrow=8)\n",
    "\n",
    "        show_grid(vis, title=f\"Epoch {epoch}\")\n",
    "\n",
    "        # ================= SAVE =================\n",
    "\n",
    "        if val_recon < best_val:\n",
    "            best_val = val_recon\n",
    "            torch.save(vae.state_dict(), best_model)\n",
    "            print(\"New best model saved\")\n",
    "\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model\": vae.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"scaler\": scaler.state_dict(),\n",
    "            \"best_val\": best_val\n",
    "        }, ckpt_file)\n",
    "\n",
    "        print(\"Checkpoint saved\")\n",
    "\n",
    "    print(\"\\nTraining complete\")\n",
    "\n",
    "# ============================================================\n",
    "# TEST\n",
    "# ============================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_vae(vae, test_loader,\n",
    "             ckpt_path=\"./vae_outputs/vae_best.pth\"):\n",
    "\n",
    "    vae.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    vae.eval()\n",
    "\n",
    "    batch = next(iter(test_loader))\n",
    "    img = batch[\"image\"][:min(8, batch[\"image\"].size(0))].to(device)\n",
    "\n",
    "    mean, logvar = vae.encode(img)\n",
    "    recon = vae.decode(mean)\n",
    "\n",
    "    show_grid(torch.cat([img, recon], dim=0),\n",
    "              title=\"Test Reconstructions\")\n",
    "\n",
    "# ============================================================\n",
    "# RUN\n",
    "# ============================================================\n",
    "\n",
    "vae = VAE(z_channels=8).to(device)\n",
    "\n",
    "train_vae(vae, train_loader, val_loader)\n",
    "\n",
    "check_latent_stochasticity(vae, train_loader)\n",
    "\n",
    "test_vae(vae, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14-02-2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import lpips\n",
    "\n",
    "# ============================================================\n",
    "# DEVICE\n",
    "# ============================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# SAFE NORMALIZATION\n",
    "# ============================================================\n",
    "\n",
    "def normalize_batch(x):\n",
    "    if x.max() > 1.5:\n",
    "        x = x / 127.5 - 1\n",
    "    elif x.min() >= 0:\n",
    "        x = x * 2 - 1\n",
    "    return x.clamp(-1, 1)\n",
    "\n",
    "# ============================================================\n",
    "# PERCEPTUAL LOSS\n",
    "# ============================================================\n",
    "\n",
    "lpips_loss = lpips.LPIPS(net='vgg').to(device)\n",
    "lpips_loss.eval()\n",
    "\n",
    "for p in lpips_loss.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "def perceptual_loss(pred, target):\n",
    "    pred3 = pred.repeat(1,3,1,1)\n",
    "    target3 = target.repeat(1,3,1,1)\n",
    "    return lpips_loss(pred3, target3).mean()\n",
    "\n",
    "# ============================================================\n",
    "# LOSSES\n",
    "# ============================================================\n",
    "\n",
    "def kl_loss(mean, logvar):\n",
    "    logvar = torch.clamp(logvar, -30, 20)\n",
    "    return -0.5 * torch.sum(\n",
    "        1 + logvar - mean.pow(2) - logvar.exp(),\n",
    "        dim=[1,2,3]\n",
    "    ).mean()\n",
    "\n",
    "def recon_loss(pred, target):\n",
    "    return F.l1_loss(pred, target)\n",
    "\n",
    "# ============================================================\n",
    "# PREVIEW STRETCH\n",
    "# ============================================================\n",
    "\n",
    "def stretch(x):\n",
    "    x = x - x.min()\n",
    "    x = x / (x.max() + 1e-8)\n",
    "    return x * 2 - 1\n",
    "\n",
    "# ============================================================\n",
    "# DISPLAY GRID\n",
    "# ============================================================\n",
    "\n",
    "def show_grid(tensor, title=\"\"):\n",
    "    tensor = (tensor + 1) / 2\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "\n",
    "    grid = make_grid(tensor, nrow=4)\n",
    "    grid = grid.cpu().permute(1,2,0).numpy()\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(grid.squeeze(), cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def train_vae(vae, train_loader, val_loader,\n",
    "              epochs=150, lr=1e-4,\n",
    "              out_dir=\"./vae_outputs\"):\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    preview_dir = os.path.join(out_dir, \"previews\")\n",
    "    os.makedirs(preview_dir, exist_ok=True)\n",
    "\n",
    "    vae = vae.to(device)\n",
    "    optimizer = torch.optim.AdamW(vae.parameters(), lr=lr)\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type==\"cuda\"))\n",
    "\n",
    "    preview = normalize_batch(\n",
    "        next(iter(val_loader))[\"image\"][:4].to(device)\n",
    "    )\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        beta = 1e-4\n",
    "\n",
    "        # ✅ perceptual gentle warmup\n",
    "        perc_weight = min(0.02, epoch * 0.005)\n",
    "\n",
    "        vae.train()\n",
    "        total_recon = 0\n",
    "\n",
    "        pbar = tqdm(train_loader,\n",
    "                    desc=f\"[TRAIN] Epoch {epoch}/{epochs}\")\n",
    "\n",
    "        for batch in pbar:\n",
    "            img = normalize_batch(batch[\"image\"].to(device))\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\",\n",
    "                                    enabled=(device.type==\"cuda\")):\n",
    "\n",
    "                recon, mean, logvar = vae(img)\n",
    "\n",
    "                loss_l1 = recon_loss(recon, img)\n",
    "                loss_p  = perceptual_loss(recon, img)\n",
    "                loss_k  = kl_loss(mean, logvar)\n",
    "\n",
    "                loss = loss_l1 + perc_weight*loss_p + beta*loss_k\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(\"NaN detected — stopping\")\n",
    "                return\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(vae.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_recon += loss_l1.item()\n",
    "\n",
    "            pbar.set_postfix(\n",
    "                L1=f\"{loss_l1.item():.4f}\",\n",
    "                KL=f\"{loss_k.item():.4f}\",\n",
    "                pw=f\"{perc_weight:.3f}\"\n",
    "            )\n",
    "\n",
    "        total_recon /= len(train_loader)\n",
    "\n",
    "        # ===== VALIDATION =====\n",
    "\n",
    "        vae.eval()\n",
    "        val_recon = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                img = normalize_batch(batch[\"image\"].to(device))\n",
    "                mean, logvar = vae.encode(img)\n",
    "                recon = vae.decode(mean)\n",
    "                val_recon += recon_loss(recon, img).item()\n",
    "\n",
    "        val_recon /= len(val_loader)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}\")\n",
    "        print(f\"Train L1: {total_recon:.4f} | Val L1: {val_recon:.4f}\")\n",
    "\n",
    "        # ===== PREVIEW =====\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mean, logvar = vae.encode(preview)\n",
    "            recon = vae.decode(mean)\n",
    "\n",
    "        vis = torch.cat([preview, stretch(recon)], dim=0)\n",
    "\n",
    "        save_image((vis+1)/2,\n",
    "                   os.path.join(preview_dir,\n",
    "                   f\"epoch_{epoch}.png\"),\n",
    "                   nrow=4)\n",
    "\n",
    "        show_grid(vis, title=f\"Epoch {epoch}\")\n",
    "\n",
    "        # ===== SAVE =====\n",
    "\n",
    "        if val_recon < best_val:\n",
    "            best_val = val_recon\n",
    "            torch.save(vae.state_dict(),\n",
    "                       os.path.join(out_dir,\n",
    "                       \"vae_best.pth\"))\n",
    "            print(\"New best model saved\")\n",
    "\n",
    "    print(\"\\nTraining complete\")\n",
    "\n",
    "# ============================================================\n",
    "# RUN\n",
    "# ============================================================\n",
    "\n",
    "vae = VAE(z_channels=16).to(device)\n",
    "train_vae(vae, train_loader, val_loader)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPfsrhG0nvk0YHd9O8t8dV1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
