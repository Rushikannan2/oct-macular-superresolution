{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgjCKwCz7j9z"
   },
   "source": [
    "# **Correct Code for Processing Images Min Max Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mv9s2GsF7YIk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Sir, base folder where notebook is running\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# Sir, input dataset folder (put your raw png folders here)\n",
    "PNG_ROOT = os.path.join(BASE_DIR, \"raw_png\")\n",
    "\n",
    "# Sir, output processed folder\n",
    "OUT_ROOT = os.path.join(BASE_DIR, \"processed_png\")\n",
    "\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "\n",
    "print(\"Sir, input folder:\", PNG_ROOT)\n",
    "print(\"Sir, output folder:\", OUT_ROOT)\n",
    "\n",
    "# Resize + Pad\n",
    "\n",
    "def pad_and_resize(img, target_size=512):\n",
    "    \"\"\"\n",
    "    Sir, resize image keeping aspect ratio\n",
    "    then pad using reflection to make square\n",
    "    \"\"\"\n",
    "\n",
    "    H, W = img.shape\n",
    "\n",
    "    scale = target_size / max(H, W)\n",
    "    new_H, new_W = int(H * scale), int(W * scale)\n",
    "\n",
    "    resized = cv2.resize(img, (new_W, new_H),\n",
    "                         interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    pad_H = target_size - new_H\n",
    "    pad_W = target_size - new_W\n",
    "\n",
    "    top = pad_H // 2\n",
    "    bottom = pad_H - top\n",
    "    left = pad_W // 2\n",
    "    right = pad_W - left\n",
    "\n",
    "    padded = np.pad(resized,\n",
    "                    ((top, bottom), (left, right)),\n",
    "                    mode=\"reflect\")\n",
    "\n",
    "    return padded\n",
    "\n",
    "\n",
    "# Normalize\n",
    "\n",
    "\n",
    "def normalize_to_uint8(img):\n",
    "    \"\"\"\n",
    "    Sir, normalize image to 0–255 uint8\n",
    "    \"\"\"\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    min_val = img.min()\n",
    "    max_val = img.max()\n",
    "\n",
    "    if max_val - min_val > 1e-6:\n",
    "        img = (img - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        img = np.zeros_like(img)\n",
    "\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# Processing Function\n",
    "\n",
    "def process_png_root(PNG_ROOT, OUT_ROOT,\n",
    "                     start_pid=0, end_pid=999999):\n",
    "\n",
    "    if not os.path.isdir(PNG_ROOT):\n",
    "        print(\"[ERROR] Sir, PNG folder not found:\", PNG_ROOT)\n",
    "        return\n",
    "\n",
    "    patients = [\n",
    "        p for p in os.listdir(PNG_ROOT)\n",
    "        if p.isdigit() and start_pid <= int(p) <= end_pid\n",
    "    ]\n",
    "\n",
    "    patients = sorted(patients, key=lambda x: int(x))\n",
    "\n",
    "    print(f\"Sir, found {len(patients)} patient folders\")\n",
    "\n",
    "    total_frames = 0\n",
    "\n",
    "    for pid in patients:\n",
    "        in_dir = os.path.join(PNG_ROOT, pid)\n",
    "        out_dir = os.path.join(OUT_ROOT, pid)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        frames = [f for f in os.listdir(in_dir)\n",
    "                  if f.lower().endswith(\".png\")]\n",
    "\n",
    "        if not frames:\n",
    "            continue\n",
    "\n",
    "        print(f\"Sir, processing patient {pid}: {len(frames)} images\")\n",
    "\n",
    "        for frame in frames:\n",
    "            img_path = os.path.join(in_dir, frame)\n",
    "\n",
    "            img = cv2.imread(img_path,\n",
    "                             cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if img is None:\n",
    "                print(\"[WARNING] Could not read:\", img_path)\n",
    "                continue\n",
    "\n",
    "            img = pad_and_resize(img, 512)\n",
    "            img = normalize_to_uint8(img)\n",
    "\n",
    "            out_path = os.path.join(out_dir, frame)\n",
    "            cv2.imwrite(out_path, img)\n",
    "\n",
    "            total_frames += 1\n",
    "\n",
    "    print(\"\\n========== FINAL REPORT ==========\")\n",
    "    print(\"Patients processed:\", len(patients))\n",
    "    print(\"Total images saved:\", total_frames)\n",
    "    print(\"==================================\\n\")\n",
    "\n",
    "# RUN PROCESSING\n",
    "\n",
    "START_PATIENT_ID = 1001\n",
    "END_PATIENT_ID = 7411\n",
    "\n",
    "process_png_root(PNG_ROOT, OUT_ROOT,\n",
    "                 START_PATIENT_ID,\n",
    "                 END_PATIENT_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx7RAldrtis4"
   },
   "source": [
    "# **WHole Dataset Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBLsEi9PtjG6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Sir, base folder where notebook runs\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# Sir, input = processed images from previous step\n",
    "DATA_ROOT = os.path.join(BASE_DIR, \"processed_png\")\n",
    "\n",
    "# Sir, output dataset split folder\n",
    "OUT_ROOT = os.path.join(BASE_DIR, \"dataset\")\n",
    "\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "\n",
    "print(\"Sir, source folder:\", DATA_ROOT)\n",
    "print(\"Sir, dataset output:\", OUT_ROOT)\n",
    "\n",
    "\n",
    "def split_full_dataset(\n",
    "    data_root,\n",
    "    out_root,\n",
    "    train_ratio=0.85,\n",
    "    val_ratio=0.10,\n",
    "    test_ratio=0.05,\n",
    "    seed=42\n",
    "):\n",
    "    random.seed(seed)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Scan patient folders\n",
    "    # -------------------------------\n",
    "    patients = []\n",
    "    for pid in os.listdir(data_root):\n",
    "        pid_path = os.path.join(data_root, pid)\n",
    "        if os.path.isdir(pid_path):\n",
    "            png_count = len([\n",
    "                f for f in os.listdir(pid_path)\n",
    "                if f.lower().endswith(\".png\")\n",
    "            ])\n",
    "            if png_count > 0:\n",
    "                patients.append((pid, png_count))\n",
    "\n",
    "    print(f\"Sir, total patients found: {len(patients)}\")\n",
    "\n",
    "    random.shuffle(patients)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Patient-level split\n",
    "    # -------------------------------\n",
    "    total_p = len(patients)\n",
    "\n",
    "    n_train = int(total_p * train_ratio)\n",
    "    n_val   = int(total_p * val_ratio)\n",
    "    n_test  = total_p - n_train - n_val\n",
    "\n",
    "    train_p = patients[:n_train]\n",
    "    val_p   = patients[n_train:n_train + n_val]\n",
    "    test_p  = patients[n_train + n_val:]\n",
    "\n",
    "    print(\"\\nSir, split summary:\")\n",
    "    print(\"Train patients:\", len(train_p))\n",
    "    print(\"Val patients:\", len(val_p))\n",
    "    print(\"Test patients:\", len(test_p))\n",
    "    print()\n",
    "\n",
    "    # -------------------------------\n",
    "    # Create split folders\n",
    "    # -------------------------------\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        os.makedirs(os.path.join(out_root, split), exist_ok=True)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Copy patient folders\n",
    "    # -------------------------------\n",
    "    for split_name, split_list in zip(\n",
    "        [\"train\", \"val\", \"test\"],\n",
    "        [train_p, val_p, test_p]\n",
    "    ):\n",
    "        split_path = os.path.join(out_root, split_name)\n",
    "\n",
    "        for pid, _ in split_list:\n",
    "            src = os.path.join(data_root, pid)\n",
    "            dst = os.path.join(split_path, pid)\n",
    "\n",
    "            if os.path.exists(dst):\n",
    "                shutil.rmtree(dst)\n",
    "\n",
    "            shutil.copytree(src, dst)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Count images\n",
    "    # -------------------------------\n",
    "    print(\"Sir, image counts per split:\")\n",
    "    total_all = 0\n",
    "\n",
    "    for split_name in [\"train\", \"val\", \"test\"]:\n",
    "        split_path = os.path.join(out_root, split_name)\n",
    "        count = 0\n",
    "\n",
    "        for pid in os.listdir(split_path):\n",
    "            pid_path = os.path.join(split_path, pid)\n",
    "            if os.path.isdir(pid_path):\n",
    "                count += len([\n",
    "                    f for f in os.listdir(pid_path)\n",
    "                    if f.lower().endswith(\".png\")\n",
    "                ])\n",
    "\n",
    "        print(f\"{split_name.upper()}: {count}\")\n",
    "        total_all += count\n",
    "\n",
    "    print(\"\\nSir, TOTAL PNG FILES:\", total_all)\n",
    "    print(\"Sir, dataset split complete ✓\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN SPLIT\n",
    "# ============================================================\n",
    "\n",
    "split_full_dataset(DATA_ROOT, OUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa4zPfOe8r2O"
   },
   "source": [
    "# **Environment Setup + Paths + Device + Helpers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twAmUyFX8sUU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Sir, set random seed for reproducibility\n",
    "# ============================================================\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DATASET PATHS (Notebook portable)\n",
    "# ============================================================\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# Sir, dataset folder should be placed inside notebook folder\n",
    "ROOT = os.path.join(BASE_DIR, \"dataset\")\n",
    "\n",
    "TRAIN_DIR = os.path.join(ROOT, \"train\")\n",
    "VAL_DIR = os.path.join(ROOT, \"val\")\n",
    "TEST_DIR = os.path.join(ROOT, \"test\")\n",
    "\n",
    "print(\"Sir, train folder:\", TRAIN_DIR)\n",
    "print(\"Sir, val folder:\", VAL_DIR)\n",
    "print(\"Sir, test folder:\", TEST_DIR)\n",
    "\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    raise FileNotFoundError(\"Sir, train directory not found\")\n",
    "if not os.path.exists(VAL_DIR):\n",
    "    raise FileNotFoundError(\"Sir, validation directory not found\")\n",
    "if not os.path.exists(TEST_DIR):\n",
    "    raise FileNotFoundError(\"Sir, test directory not found\")\n",
    "\n",
    "print(\"Sir, dataset folders verified ✓\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# OUTPUT FOLDERS\n",
    "# ============================================================\n",
    "\n",
    "OUT_ROOT = os.path.join(BASE_DIR, \"oct_ldm_output\")\n",
    "\n",
    "DIR_SAMPLES = os.path.join(OUT_ROOT, \"samples\")\n",
    "DIR_CHECKPOINTS = os.path.join(OUT_ROOT, \"checkpoints\")\n",
    "DIR_PLOTS = os.path.join(OUT_ROOT, \"plots\")\n",
    "DIR_JSON = os.path.join(OUT_ROOT, \"json\")\n",
    "DIR_CSV = os.path.join(OUT_ROOT, \"csv\")\n",
    "\n",
    "os.makedirs(DIR_SAMPLES, exist_ok=True)\n",
    "os.makedirs(DIR_CHECKPOINTS, exist_ok=True)\n",
    "os.makedirs(DIR_PLOTS, exist_ok=True)\n",
    "os.makedirs(DIR_JSON, exist_ok=True)\n",
    "os.makedirs(DIR_CSV, exist_ok=True)\n",
    "\n",
    "print(\"Sir, output folders created at:\", OUT_ROOT)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DEVICE\n",
    "# ============================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Sir, GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# VISUALIZATION FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def show_grid(tensor, nrow=8, title=\"\"):\n",
    "    tensor = tensor.detach()\n",
    "\n",
    "    grid = make_grid(tensor.clamp(-1, 1), nrow=nrow, normalize=False)\n",
    "    grid = grid.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    if grid.shape[-1] == 1:\n",
    "        plt.imshow(grid[..., 0], cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(grid)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Sir, local OCT LDM environment ready ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlVZpBdH9pT6"
   },
   "source": [
    "# **Dataset Construction & DataLoader Interface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_J3lK5Q9pwM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ============================================================\n",
    "# DATASET CLASS\n",
    "# ============================================================\n",
    "\n",
    "class OCTDataset(Dataset):\n",
    "    def __init__(self, root, image_size=512, recursive=True):\n",
    "        self.root = root\n",
    "        self.image_size = image_size\n",
    "\n",
    "        if not os.path.exists(root):\n",
    "            raise FileNotFoundError(f\"Sir, dataset folder not found: {root}\")\n",
    "\n",
    "        pattern = \"**/*.png\" if recursive else \"*.png\"\n",
    "        self.paths = sorted(glob.glob(os.path.join(root, pattern), recursive=recursive))\n",
    "\n",
    "        if len(self.paths) == 0:\n",
    "            raise RuntimeError(f\"Sir, no PNG files found in {root}\")\n",
    "\n",
    "        print(f\"Sir, loaded {len(self.paths)} OCT scans from {root}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def _load_oct_image(self, path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise RuntimeError(f\"Sir, failed to load image: {path}\")\n",
    "        return img\n",
    "\n",
    "    def _pad_keep_aspect(self, img):\n",
    "        h, w = img.shape\n",
    "        target = self.image_size\n",
    "\n",
    "        scale = min(target / h, target / w)\n",
    "        new_h, new_w = int(h * scale), int(w * scale)\n",
    "\n",
    "        img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        pad_h = target - new_h\n",
    "        pad_w = target - new_w\n",
    "\n",
    "        top = pad_h // 2\n",
    "        bottom = pad_h - top\n",
    "        left = pad_w // 2\n",
    "        right = pad_w - left\n",
    "\n",
    "        img_padded = cv2.copyMakeBorder(\n",
    "            img_resized,\n",
    "            top,\n",
    "            bottom,\n",
    "            left,\n",
    "            right,\n",
    "            borderType=cv2.BORDER_REFLECT_101\n",
    "        )\n",
    "\n",
    "        return img_padded\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "\n",
    "        img = self._load_oct_image(path)\n",
    "        img = self._pad_keep_aspect(img)\n",
    "\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img = img.unsqueeze(0)\n",
    "        img = (img / 255.0) * 2.0 - 1.0\n",
    "\n",
    "        patient = os.path.basename(os.path.dirname(path))\n",
    "\n",
    "        return {\n",
    "            \"image\": img,\n",
    "            \"patient\": patient,\n",
    "            \"path\": path\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# BUILD LOADERS (connected to previous pipeline)\n",
    "# ============================================================\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_ROOT = os.path.join(BASE_DIR, \"dataset\")\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, \"train\")\n",
    "VAL_DIR = os.path.join(DATA_ROOT, \"val\")\n",
    "TEST_DIR = os.path.join(DATA_ROOT, \"test\")\n",
    "\n",
    "print(\"Sir, using dataset folder:\", DATA_ROOT)\n",
    "\n",
    "train_loader, val_loader, test_loader = None, None, None\n",
    "\n",
    "def build_loaders(batch_size=4, num_workers=2, image_size=512):\n",
    "\n",
    "    train_ds = OCTDataset(TRAIN_DIR, image_size=image_size)\n",
    "    val_ds   = OCTDataset(VAL_DIR, image_size=image_size)\n",
    "    test_ds  = OCTDataset(TEST_DIR, image_size=image_size)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CREATE LOADERS\n",
    "# ============================================================\n",
    "\n",
    "train_loader, val_loader, test_loader = build_loaders()\n",
    "\n",
    "print(\"Sir, data loaders ready ✓\")\n",
    "print(\"Train batches:\", len(train_loader))\n",
    "print(\"Val batches:\", len(val_loader))\n",
    "print(\"Test batches:\", len(test_loader))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# QUICK SANITY TEST\n",
    "# ============================================================\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(\"Sample batch image shape:\", batch[\"image\"].shape)\n",
    "print(\"Sample patients:\", batch[\"patient\"][:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7nhkEOt-jZ5"
   },
   "source": [
    "# **Patient-wise OCT Cohort Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-e1ryKf-k0Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "\n",
    "# ============================================================\n",
    "# LINK TO PREVIOUS PIPELINE\n",
    "# ============================================================\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_ROOT = os.path.join(BASE_DIR, \"dataset\")\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, \"train\")\n",
    "VAL_DIR   = os.path.join(DATA_ROOT, \"val\")\n",
    "TEST_DIR  = os.path.join(DATA_ROOT, \"test\")\n",
    "\n",
    "print(\"Sir, inspecting dataset at:\", DATA_ROOT)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# INSPECTION FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def inspect_oct_dataset(root):\n",
    "    if not os.path.exists(root):\n",
    "        raise FileNotFoundError(f\"Sir, directory not found: {root}\")\n",
    "\n",
    "    print(f\"\\nInspecting directory: {root}\")\n",
    "\n",
    "    all_paths = sorted(glob.glob(os.path.join(root, \"**\", \"*.png\"), recursive=True))\n",
    "    total_images = len(all_paths)\n",
    "\n",
    "    print(f\"Total PNG images: {total_images}\")\n",
    "\n",
    "    patient_counts = defaultdict(int)\n",
    "\n",
    "    for path in all_paths:\n",
    "        patient = os.path.basename(os.path.dirname(path))\n",
    "        patient_counts[patient] += 1\n",
    "\n",
    "    num_patients = len(patient_counts)\n",
    "\n",
    "    if num_patients > 0:\n",
    "        counts = list(patient_counts.values())\n",
    "        print(f\"Patients: {num_patients}\")\n",
    "        print(f\"Minimum images per patient: {min(counts)}\")\n",
    "        print(f\"Maximum images per patient: {max(counts)}\")\n",
    "        print(f\"Average images per patient: {sum(counts) / num_patients:.2f}\")\n",
    "    else:\n",
    "        print(\"Sir, no patient folders detected\")\n",
    "\n",
    "    return num_patients, total_images\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN INSPECTION\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nTRAIN DATASET\")\n",
    "train_patients, train_images = inspect_oct_dataset(TRAIN_DIR)\n",
    "\n",
    "print(\"\\nVALIDATION DATASET\")\n",
    "val_patients, val_images = inspect_oct_dataset(VAL_DIR)\n",
    "\n",
    "print(\"\\nTEST DATASET\")\n",
    "test_patients, test_images = inspect_oct_dataset(TEST_DIR)\n",
    "\n",
    "\n",
    "print(\"\\nDATASET SUMMARY\")\n",
    "print(f\"Train  -> {train_patients} patients, {train_images} images\")\n",
    "print(f\"Val    -> {val_patients} patients, {val_images} images\")\n",
    "print(f\"Test   -> {test_patients} patients, {test_images} images\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SAMPLE IMAGE CHECK\n",
    "# ============================================================\n",
    "\n",
    "sample_files = glob.glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"), recursive=True)\n",
    "\n",
    "if sample_files:\n",
    "    img = cv2.imread(sample_files[0], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is not None:\n",
    "        print(f\"\\nSir, sample image resolution: {img.shape} (H, W)\")\n",
    "    else:\n",
    "        print(\"\\nSir, failed to load sample image\")\n",
    "else:\n",
    "    print(\"\\nSir, no PNG files found in training directory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBr1V6ieg5sD"
   },
   "source": [
    "# **Variational Autoencoder (VAE) Architecture for OCT Image Reconstruction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jArqexH7g-7r"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Sir, this sets the folder where the notebook is running\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# Sir, we create an output folder to save images\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"outputs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Sir, this checks if GPU is available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# Sir, this function creates safe normalization\n",
    "def norm_layer(ch):\n",
    "    return nn.GroupNorm(min(32, ch), ch)\n",
    "\n",
    "\n",
    "# Sir, this is a residual block\n",
    "# It helps the model learn better features\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(ch)\n",
    "        self.conv1 = nn.Conv2d(ch, ch, 3, padding=1)\n",
    "        self.norm2 = norm_layer(ch)\n",
    "        self.conv2 = nn.Conv2d(ch, ch, 3, padding=1)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(self.act(self.norm1(x)))\n",
    "        h = self.conv2(self.act(self.norm2(h)))\n",
    "        return x + h   # Sir, skip connection\n",
    "\n",
    "\n",
    "# Sir, this block reduces image size (downsampling)\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 4, 2, 1)\n",
    "        self.norm = norm_layer(out_ch)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "# Sir, this block increases image size (upsampling)\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(in_ch, out_ch, 4, 2, 1)\n",
    "        self.norm = norm_layer(out_ch)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "# Sir, this is the full Variational Autoencoder model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, im_channels=1, z_channels=8, base_ch=64):\n",
    "        super().__init__()\n",
    "\n",
    "        # Sir, encoder part\n",
    "        self.conv_in = nn.Conv2d(im_channels, base_ch, 3, padding=1)\n",
    "\n",
    "        self.down1 = DownBlock(base_ch, base_ch * 2)\n",
    "        self.res1  = ResBlock(base_ch * 2)\n",
    "\n",
    "        self.down2 = DownBlock(base_ch * 2, base_ch * 4)\n",
    "        self.res2  = ResBlock(base_ch * 4)\n",
    "\n",
    "        self.down3 = DownBlock(base_ch * 4, base_ch * 4)\n",
    "        self.res3  = ResBlock(base_ch * 4)\n",
    "\n",
    "        mid_ch = base_ch * 4\n",
    "\n",
    "        # Sir, latent mean and variance\n",
    "        self.to_stats = nn.Conv2d(mid_ch, z_channels * 2, 3, padding=1)\n",
    "\n",
    "        # Sir, decoder part\n",
    "        self.from_latent = nn.Conv2d(z_channels, mid_ch, 3, padding=1)\n",
    "\n",
    "        self.res4 = ResBlock(mid_ch)\n",
    "\n",
    "        self.up1 = UpBlock(mid_ch, base_ch * 4)\n",
    "        self.res5 = ResBlock(base_ch * 4)\n",
    "\n",
    "        self.up2 = UpBlock(base_ch * 4, base_ch * 2)\n",
    "        self.res6 = ResBlock(base_ch * 2)\n",
    "\n",
    "        self.up3 = UpBlock(base_ch * 2, base_ch)\n",
    "        self.res7 = ResBlock(base_ch)\n",
    "\n",
    "        self.norm_out = norm_layer(base_ch)\n",
    "        self.conv_out = nn.Conv2d(base_ch, im_channels, 3, padding=1)\n",
    "\n",
    "    # Sir, encoding step\n",
    "    def encode(self, x):\n",
    "        x = self.conv_in(x)\n",
    "        x = self.res1(self.down1(x))\n",
    "        x = self.res2(self.down2(x))\n",
    "        x = self.res3(self.down3(x))\n",
    "\n",
    "        stats = self.to_stats(x)\n",
    "        mean, logvar = torch.chunk(stats, 2, dim=1)\n",
    "\n",
    "        # Sir, clamp prevents explosion\n",
    "        logvar = torch.clamp(logvar, -10, 10)\n",
    "        return mean, logvar\n",
    "\n",
    "    # Sir, reparameterization trick\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    # Sir, decoding step\n",
    "    def decode(self, z):\n",
    "        x = self.from_latent(z)\n",
    "        x = self.res4(x)\n",
    "        x = self.res5(self.up1(x))\n",
    "        x = self.res6(self.up2(x))\n",
    "        x = self.res7(self.up3(x))\n",
    "        x = self.conv_out(F.silu(self.norm_out(x)))\n",
    "        return torch.tanh(x)\n",
    "\n",
    "    # Sir, full forward pass\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mean, logvar\n",
    "\n",
    "\n",
    "# Sir, testing the model\n",
    "vae = VAE().to(device)\n",
    "vae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = torch.randn(1, 1, 512, 512).to(device)\n",
    "    recon, mean, logvar = vae(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Latent shape:\", mean.shape)\n",
    "print(\"Reconstruction shape:\", recon.shape)\n",
    "\n",
    "# Sir, save output image\n",
    "out_path = os.path.join(OUTPUT_DIR, \"reconstruction.png\")\n",
    "save_image((recon + 1) / 2, out_path)\n",
    "print(\"Saved image to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gB-pKjwtwX8n"
   },
   "source": [
    "# **OCT Dataset Loader for Training, Validation, and Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bLbJy8Sl4wL"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "# Sir, this dataset class loads OCT images from folder\n",
    "class OCTDataset(Dataset):\n",
    "    def __init__(self, root, image_size=512):\n",
    "        self.paths = sorted(glob.glob(os.path.join(root, \"**/*.png\"), recursive=True))\n",
    "        self.image_size = image_size\n",
    "\n",
    "        if len(self.paths) == 0:\n",
    "            raise RuntimeError(f\"Sir, no images found in {root}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "\n",
    "        # Sir, read grayscale image\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img is None:\n",
    "            raise RuntimeError(f\"Sir, failed to load image: {path}\")\n",
    "\n",
    "        # Sir, resize to fixed size (important for VAE)\n",
    "        img = cv2.resize(img, (self.image_size, self.image_size),\n",
    "                         interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Sir, convert to tensor and normalize to [-1,1]\n",
    "        img = torch.from_numpy(img).float().contiguous()\n",
    "        img = img / 255.0\n",
    "        img = img.unsqueeze(0) * 2 - 1\n",
    "\n",
    "        return {\"image\": img}\n",
    "\n",
    "# LOCAL PATH SETUP\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# Sir, dataset folder should be inside notebook folder\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"dataset\")\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "VAL_DIR   = os.path.join(DATA_DIR, \"val\")\n",
    "TEST_DIR  = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "print(\"Sir, dataset folder:\", DATA_DIR)\n",
    "\n",
    "\n",
    "# LOAD DATASETS\n",
    "\n",
    "train_ds = OCTDataset(TRAIN_DIR)\n",
    "val_ds   = OCTDataset(VAL_DIR)\n",
    "test_ds  = OCTDataset(TEST_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,\n",
    "                          num_workers=0, pin_memory=True)\n",
    "\n",
    "val_loader   = DataLoader(val_ds, batch_size=4,\n",
    "                          num_workers=0, pin_memory=True)\n",
    "\n",
    "test_loader  = DataLoader(test_ds, batch_size=4,\n",
    "                          num_workers=0, pin_memory=True)\n",
    "\n",
    "print(\"Sir, loaders ready ✓\")\n",
    "print(\"Train images:\", len(train_ds))\n",
    "print(\"Val images:\", len(val_ds))\n",
    "print(\"Test images:\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpklMLB3wnYl"
   },
   "source": [
    "# **VAE Training and Evaluation Pipeline for OCT Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ef3TzHmYmAsF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "# Sir, base working directory (notebook folder)\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# Sir, create training output folder\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"vae_outputs\")\n",
    "PREVIEW_DIR = os.path.join(OUT_DIR, \"previews\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(PREVIEW_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Sir, outputs will be saved in:\", OUT_DIR)\n",
    "\n",
    "# Sir, device selection\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# LOSSES\n",
    "\n",
    "# Sir, KL divergence loss\n",
    "def kl_loss(mean, logvar):\n",
    "    return -0.5 * torch.sum(\n",
    "        1 + logvar - mean.pow(2) - logvar.exp(),\n",
    "        dim=[1, 2, 3]\n",
    "    ).mean()\n",
    "\n",
    "# Sir, reconstruction loss\n",
    "def recon_loss(pred, target):\n",
    "    return F.l1_loss(pred, target)\n",
    "\n",
    "# VISUALIZATION\n",
    "\n",
    "# Sir, display image grid\n",
    "def show_grid(tensor, title=\"\"):\n",
    "    tensor = (tensor + 1) / 2\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "\n",
    "    grid = make_grid(tensor, nrow=8)\n",
    "    grid = grid.cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(grid.squeeze(), cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# STOCHASTIC CHECK\n",
    "\n",
    "@torch.no_grad()\n",
    "def check_latent_stochasticity(vae, loader):\n",
    "    vae.eval()\n",
    "\n",
    "    batch = next(iter(loader))\n",
    "    x = batch[\"image\"].to(device)\n",
    "\n",
    "    mean, logvar = vae.encode(x)\n",
    "\n",
    "    z1 = vae.reparameterize(mean, logvar)\n",
    "    z2 = vae.reparameterize(mean, logvar)\n",
    "\n",
    "    diff = torch.mean(torch.abs(z1 - z2))\n",
    "    print(\"Sir, latent stochastic difference:\", diff.item())\n",
    "\n",
    "# TRAIN FUNCTION\n",
    "\n",
    "def train_vae(vae, train_loader, val_loader,\n",
    "              epochs=70, lr=1e-4):\n",
    "\n",
    "    vae = vae.to(device)\n",
    "\n",
    "    ckpt_file = os.path.join(OUT_DIR, \"resume_checkpoint.pt\")\n",
    "    best_model = os.path.join(OUT_DIR, \"vae_best.pth\")\n",
    "\n",
    "    optimizer = torch.optim.AdamW(vae.parameters(), lr=lr)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    start_epoch = 1\n",
    "    best_val = float(\"inf\")\n",
    "\n",
    "    # Sir, resume training if checkpoint exists\n",
    "    if os.path.exists(ckpt_file):\n",
    "        ckpt = torch.load(ckpt_file, map_location=device)\n",
    "        vae.load_state_dict(ckpt[\"model\"])\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "        scaler.load_state_dict(ckpt[\"scaler\"])\n",
    "        start_epoch = ckpt[\"epoch\"] + 1\n",
    "        best_val = ckpt[\"best_val\"]\n",
    "        print(\"Sir, resuming from epoch\", start_epoch)\n",
    "\n",
    "    preview = next(iter(val_loader))[\"image\"]\n",
    "    preview = preview[:min(8, preview.size(0))].to(device)\n",
    "\n",
    "    # TRAIN LOOP\n",
    "\n",
    "    for epoch in range(start_epoch, epochs + 1):\n",
    "\n",
    "        beta = 0.01 * min(1.0, epoch / 100)\n",
    "\n",
    "        vae.train()\n",
    "        total_recon = 0\n",
    "\n",
    "        pbar = tqdm(train_loader,\n",
    "                    desc=f\"[TRAIN] Epoch {epoch}/{epochs}\")\n",
    "\n",
    "        for batch in pbar:\n",
    "            img = batch[\"image\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "                recon, mean, logvar = vae(img)\n",
    "                loss_r = recon_loss(recon, img)\n",
    "                loss_k = kl_loss(mean, logvar)\n",
    "                loss = 10 * loss_r + beta * loss_k\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(vae.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_recon += loss_r.item()\n",
    "\n",
    "            pbar.set_postfix(L1=f\"{loss_r.item():.4f}\",\n",
    "                             KL=f\"{loss_k.item():.4f}\")\n",
    "\n",
    "        total_recon /= len(train_loader)\n",
    "\n",
    "        #  VALIDATION\n",
    "\n",
    "        vae.eval()\n",
    "        val_recon = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                img = batch[\"image\"].to(device)\n",
    "\n",
    "                mean, logvar = vae.encode(img)\n",
    "                recon = vae.decode(mean)\n",
    "\n",
    "                val_recon += recon_loss(recon, img).item()\n",
    "\n",
    "        val_recon /= len(val_loader)\n",
    "\n",
    "        print(f\"\\nSir, Epoch {epoch}\")\n",
    "        print(f\"Train L1: {total_recon:.4f} | Val L1: {val_recon:.4f}\")\n",
    "\n",
    "        #  PREVIEW SAVE\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mean, logvar = vae.encode(preview)\n",
    "            recon = vae.decode(mean)\n",
    "\n",
    "        vis = torch.cat([preview, recon], dim=0)\n",
    "\n",
    "        save_path = os.path.join(PREVIEW_DIR,\n",
    "                                 f\"epoch_{epoch}.png\")\n",
    "        save_image((vis + 1) / 2, save_path, nrow=8)\n",
    "\n",
    "        show_grid(vis, title=f\"Epoch {epoch}\")\n",
    "\n",
    "        # SAVE MODEL\n",
    "\n",
    "        if val_recon < best_val:\n",
    "            best_val = val_recon\n",
    "            torch.save(vae.state_dict(), best_model)\n",
    "            print(\"Sir, new best model saved\")\n",
    "\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model\": vae.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"scaler\": scaler.state_dict(),\n",
    "            \"best_val\": best_val\n",
    "        }, ckpt_file)\n",
    "\n",
    "        print(\"Sir, checkpoint saved\")\n",
    "\n",
    "    print(\"\\nSir, training complete\")\n",
    "\n",
    "# TEST FUNCTION\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_vae(vae, test_loader):\n",
    "\n",
    "    best_model = os.path.join(OUT_DIR, \"vae_best.pth\")\n",
    "\n",
    "    vae.load_state_dict(torch.load(best_model,\n",
    "                                   map_location=device))\n",
    "    vae.eval()\n",
    "\n",
    "    batch = next(iter(test_loader))\n",
    "    img = batch[\"image\"][:8].to(device)\n",
    "\n",
    "    mean, logvar = vae.encode(img)\n",
    "    recon = vae.decode(mean)\n",
    "\n",
    "    show_grid(torch.cat([img, recon], dim=0),\n",
    "              title=\"Test Reconstructions\")\n",
    "\n",
    "# RUN\n",
    "\n",
    "vae = VAE(z_channels=8).to(device)\n",
    "\n",
    "train_vae(vae, train_loader, val_loader)\n",
    "\n",
    "check_latent_stochasticity(vae, train_loader)\n",
    "\n",
    "test_vae(vae, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNB9rMn72XRP4pt182z/EXg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
